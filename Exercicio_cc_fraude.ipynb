{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNf9rnpmrV+CbDNrgLSOjcl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fernandodalcin/DSWP/blob/DSWP_meus_nbs/Exercicio_cc_fraude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZ9Mv6tD4kkR"
      },
      "source": [
        "## Exercício 1 - Credit Card Fraud Detection\n",
        "Source: [Credit Card Fraud Detection](https://www.kaggle.com/mlg-ulb/creditcardfraud)\n",
        "\n",
        "### Leitura suporte\n",
        "* [Detecting Credit Card Fraud Using Machine Learning](https://towardsdatascience.com/detecting-credit-card-fraud-using-machine-learning-a3d83423d3b8)\n",
        "* [Credit Card Fraud Detection](https://towardsdatascience.com/credit-card-fraud-detection-a1c7e1b75f59)\n",
        "\n",
        "### Dataframe\n",
        "* [Creditcard.csv](https://raw.githubusercontent.com/MathMachado/DataFrames/master/creditcard.csv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XESMUGr7_Pc6"
      },
      "source": [
        "## **Importando Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Lyx4a9g_Nvp"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix # para plotar a confusion matrix\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV # para otimizar os parâmetros dos modelos preditivos\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score # para medir a acurácia do modelo preditivo\n",
        "\n",
        "# Importar classificador (critério, algoritmo, etc)\n",
        "from sklearn.tree import DecisionTreeClassifier # Este é o classificador\n",
        "\n",
        "from sklearn.model_selection import cross_val_score \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from time import time"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueW89FCQ4mk3",
        "outputId": "2ee9706f-5bd9-47e9-a0ae-36df07384915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "source": [
        "df_cc = pd.read_csv('https://github.com/fernandodalcin/DSWP/blob/master/Dataframes/creditcard.csv?raw=true')\n",
        "# opcional = 'https://raw.githubusercontent.com/fernandodalcin/DSWP/master/Dataframes/creditcard.csv'\n",
        "df_cc.head(10)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>-0.371407</td>\n",
              "      <td>1.341262</td>\n",
              "      <td>0.359894</td>\n",
              "      <td>-0.358091</td>\n",
              "      <td>-0.137134</td>\n",
              "      <td>0.517617</td>\n",
              "      <td>0.401726</td>\n",
              "      <td>-0.058133</td>\n",
              "      <td>0.068653</td>\n",
              "      <td>-0.033194</td>\n",
              "      <td>0.084968</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4</td>\n",
              "      <td>1.229658</td>\n",
              "      <td>0.141004</td>\n",
              "      <td>0.045371</td>\n",
              "      <td>1.202613</td>\n",
              "      <td>0.191881</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>-0.005159</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>-0.099254</td>\n",
              "      <td>-1.416907</td>\n",
              "      <td>-0.153826</td>\n",
              "      <td>-0.751063</td>\n",
              "      <td>0.167372</td>\n",
              "      <td>0.050144</td>\n",
              "      <td>-0.443587</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.611987</td>\n",
              "      <td>-0.045575</td>\n",
              "      <td>-0.219633</td>\n",
              "      <td>-0.167716</td>\n",
              "      <td>-0.270710</td>\n",
              "      <td>-0.154104</td>\n",
              "      <td>-0.780055</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>-0.257237</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>1.249376</td>\n",
              "      <td>-0.619468</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>1.757964</td>\n",
              "      <td>-1.323865</td>\n",
              "      <td>0.686133</td>\n",
              "      <td>-0.076127</td>\n",
              "      <td>-1.222127</td>\n",
              "      <td>-0.358222</td>\n",
              "      <td>0.324505</td>\n",
              "      <td>-0.156742</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.80</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>-0.410430</td>\n",
              "      <td>-0.705117</td>\n",
              "      <td>-0.110452</td>\n",
              "      <td>-0.286254</td>\n",
              "      <td>0.074355</td>\n",
              "      <td>-0.328783</td>\n",
              "      <td>-0.210077</td>\n",
              "      <td>-0.499768</td>\n",
              "      <td>0.118765</td>\n",
              "      <td>0.570328</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>93.20</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>-0.366846</td>\n",
              "      <td>1.017614</td>\n",
              "      <td>0.836390</td>\n",
              "      <td>1.006844</td>\n",
              "      <td>-0.443523</td>\n",
              "      <td>0.150219</td>\n",
              "      <td>0.739453</td>\n",
              "      <td>-0.540980</td>\n",
              "      <td>0.476677</td>\n",
              "      <td>0.451773</td>\n",
              "      <td>0.203711</td>\n",
              "      <td>-0.246914</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>3.68</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0     0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62    0.0\n",
              "1     0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69    0.0\n",
              "2     1 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66    0.0\n",
              "3     1 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50    0.0\n",
              "4     2 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99    0.0\n",
              "5     2 -0.425966  0.960523  1.141109  ...  0.253844  0.081080    3.67    0.0\n",
              "6     4  1.229658  0.141004  0.045371  ...  0.034507  0.005168    4.99    0.0\n",
              "7     7 -0.644269  1.417964  1.074380  ... -1.206921 -1.085339   40.80    0.0\n",
              "8     7 -0.894286  0.286157 -0.113192  ...  0.011747  0.142404   93.20    0.0\n",
              "9     9 -0.338262  1.119593  1.044367  ...  0.246219  0.083076    3.68    0.0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0valwh948rC"
      },
      "source": [
        "## Tratando NaNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xf6cijn5M4C",
        "outputId": "e6d54e54-8743-4cd0-ecdd-9f5fc7d8a00d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_cc.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12842, 31)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbSgo1an4rQN",
        "outputId": "c555a583-3c60-4378-cb00-5f05789250a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "df_cc.isna().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       1\n",
              "V11       1\n",
              "V12       1\n",
              "V13       1\n",
              "V14       1\n",
              "V15       1\n",
              "V16       1\n",
              "V17       1\n",
              "V18       1\n",
              "V19       1\n",
              "V20       1\n",
              "V21       1\n",
              "V22       1\n",
              "V23       1\n",
              "V24       1\n",
              "V25       1\n",
              "V26       1\n",
              "V27       1\n",
              "V28       1\n",
              "Amount    1\n",
              "Class     1\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRCjGI5A4wSQ",
        "outputId": "1ab58444-c02a-46d3-867f-afb17542a1b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "df_cc.dropna(inplace=True)\n",
        "df_cc.isna().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jxi4jkE42rl",
        "outputId": "d7920059-15f0-4b6f-beb2-17a77c0b9500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "df_cc['Class'].value_counts()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    12785\n",
              "1.0       56\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XOXeLpb5BFN"
      },
      "source": [
        "## Variáveis globais"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGp9Dgl-7Ocr"
      },
      "source": [
        "df_cc2 = df_cc.copy()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAIGdc3k5Em0"
      },
      "source": [
        "i_CV = 10 # Número de Cross-Validations\n",
        "i_Seed = 20119974 # Semente\n",
        "f_Test_Size = 0.3 # Proporção do dataframe de validação"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cVaoRiA52RK"
      },
      "source": [
        "## Definir amostras de treinamento e teste"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy03sYi_7TjK"
      },
      "source": [
        "df_X = df_cc2.drop(columns=['Class']) # Dataframe SOMENTE COM AS PREDITORAS -> Não pode conter a variável 'Class'\n",
        "df_Y = df_cc2['Class'] # Variável resposta"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzIu2mrz8Q4l",
        "outputId": "d265a57e-3cbb-458f-8ab5-88ceef32c316",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "df_Y.value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    12785\n",
              "1.0       56\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyWyVVOx52m4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_treinamento, X_teste, y_treinamento, y_teste = train_test_split(df_X, df_Y, test_size = f_Test_Size, random_state = i_Seed)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2-Hv4BG7z9C",
        "outputId": "67b92ee1-6925-42ee-a011-81cf50ae6c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_treinamento.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8988, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoY67QXg8brX",
        "outputId": "0f7c19ad-33a7-409b-b2a3-852c3b73670f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_teste.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3853, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxB-M6UQ8_8G"
      },
      "source": [
        "## Ajusta o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CkdAoXX9ryy",
        "outputId": "9bcb6021-6801-4987-ae35-b5e49c7c529b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "ml_DT= DecisionTreeClassifier(max_depth = 5, \n",
        "                              min_samples_split = 2, \n",
        "                              random_state = i_Seed)\n",
        "ml_DT"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=20119974, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3kYo9q3-VvW"
      },
      "source": [
        "## Treinar o algoritmo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsYQbsKD-arR",
        "outputId": "0c6f073c-2a30-4166-eada-978718a4003a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "ml_DT.fit(X_treinamento, y_treinamento)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=5, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=20119974, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpYYXSek-uKY",
        "outputId": "0f818a19-9861-4dca-9064-b090a7ce3363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "# Cross-Validation com 10 folds\n",
        "a_scores_CV = cross_val_score(ml_DT, X_treinamento, y_treinamento, cv = i_CV)\n",
        "\n",
        "print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "print(f'Array de scores obtidos a cada interação..: {list(a_scores_CV)}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Média das Acurácias calculadas pelo CV....: 99.87\n",
            "std médio das Acurácias calculadas pelo CV: 0.13\n",
            "Array de scores obtidos a cada interação..: [0.9977753058954394, 1.0, 0.9988876529477196, 1.0, 0.9988876529477196, 0.9955506117908788, 0.9977753058954394, 0.9988876529477196, 0.9988864142538976, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Pu3xY1LfnGe"
      },
      "source": [
        "### Acurária inicial de 99.87%, com desvio padrão de 0,13%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYO3TsWQfzLM"
      },
      "source": [
        "## Fazendo testes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW8qhL6Bedkm",
        "outputId": "88493fb3-898c-4c7b-97fa-76120a0b394a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# Faz predições...\n",
        "y_pred = ml_DT.predict(X_teste)\n",
        "y_pred[0:300]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM58yZ68gMY8"
      },
      "source": [
        "def mostra_confusion_matrix(cf, \n",
        "                            group_names = None, \n",
        "                            categories = 'auto', \n",
        "                            count = True, \n",
        "                            percent = True, \n",
        "                            cbar = True, \n",
        "                            xyticks = False, \n",
        "                            xyplotlabels = True, \n",
        "                            sum_stats = True, figsize = (8, 8), \n",
        "                            cmap = 'Blues'):\n",
        "    '''\n",
        "    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n",
        "    Arguments\n",
        "    ---------\n",
        "    cf:            confusion matrix to be passed in\n",
        "    group_names:   List of strings that represent the labels row by row to be shown in each square.\n",
        "    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n",
        "    count:         If True, show the raw number in the confusion matrix. Default is True.\n",
        "    normalize:     If True, show the proportions for each category. Default is True.\n",
        "    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n",
        "                   Default is True.\n",
        "    xyticks:       If True, show x and y ticks. Default is True.\n",
        "    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n",
        "    sum_stats:     If True, display summary statistics below the figure. Default is True.\n",
        "    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n",
        "    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n",
        "                   See http://matplotlib.org/examples/color/colormaps_reference.html\n",
        "    '''\n",
        "\n",
        "    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n",
        "    blanks = ['' for i in range(cf.size)]\n",
        "\n",
        "    if group_names and len(group_names)==cf.size:\n",
        "        group_labels = [\"{}\\n\".format(value) for value in group_names]\n",
        "    else:\n",
        "        group_labels = blanks\n",
        "\n",
        "    if count:\n",
        "        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n",
        "    else:\n",
        "        group_counts = blanks\n",
        "\n",
        "    if percent:\n",
        "        group_percentages = [\"{0:.2%}\".format(value) for value in cf.flatten()/np.sum(cf)]\n",
        "    else:\n",
        "        group_percentages = blanks\n",
        "\n",
        "    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n",
        "    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n",
        "\n",
        "    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n",
        "    if sum_stats:\n",
        "        #Accuracy is sum of diagonal divided by total observations\n",
        "        accuracy  = np.trace(cf) / float(np.sum(cf))\n",
        "\n",
        "        #if it is a binary confusion matrix, show some more stats\n",
        "        if len(cf)==2:\n",
        "            #Metrics for Binary Confusion Matrices\n",
        "            precision = cf[1,1] / sum(cf[:,1])\n",
        "            recall    = cf[1,1] / sum(cf[1,:])\n",
        "            f1_score  = 2*precision*recall / (precision + recall)\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(accuracy,precision,recall,f1_score)\n",
        "        else:\n",
        "            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n",
        "    else:\n",
        "        stats_text = \"\"\n",
        "\n",
        "    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n",
        "    if figsize==None:\n",
        "        #Get default figure size if not set\n",
        "        figsize = plt.rcParams.get('figure.figsize')\n",
        "\n",
        "    if xyticks==False:\n",
        "        #Do not show categories if xyticks is False\n",
        "        categories=False\n",
        "\n",
        "    # MAKE THE HEATMAP VISUALIZATION\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n",
        "\n",
        "    if xyplotlabels:\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label' + stats_text)\n",
        "    else:\n",
        "        plt.xlabel(stats_text)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdZtHn8jiwuM",
        "outputId": "e77f095f-bbb9-4fa0-8f66-d8e5017dd924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "# Confusion Matrix\n",
        "cf_matrix = confusion_matrix(y_teste, y_pred)\n",
        "cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "cf_categories = ['Zero', 'One']\n",
        "mostra_confusion_matrix(cf_matrix, group_names= cf_labels, categories= cf_categories)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfnYdlsDjRId"
      },
      "source": [
        "## Parameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ius0cnvykX43"
      },
      "source": [
        "# Dicionário de parâmetros para o parameter tunning. Ao todo serão ajustados 2X13X5X5X7= 4.550 modelos. Contando com 10 folds no Cross-Validation, então são 45.500 modelos.\n",
        "d_parametros_DT= {\"criterion\": [\"gini\", \"entropy\"],\n",
        "                  \"min_samples_split\": [2, 5, 10, 30, 50, 70, 90, 120, 150, 180, 210, 240, 270, 350, 400],\n",
        "                  \"max_depth\": [None, 2, 5, 9, 15],\n",
        "                  \"min_samples_leaf\": [20, 40, 60, 80, 100],\n",
        "                  \"max_leaf_nodes\": [None, 2, 3, 4, 5, 10, 15]}"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhhriTONjS5q"
      },
      "source": [
        "# Definindo a função para o GridSearchCV\n",
        "def GridSearchOptimizer(modelo, ml_Opt, d_Parametros, X_train, y_train, X_test, y_test, cv = i_CV):\n",
        "    ml_GridSearchCV = GridSearchCV(modelo, d_Parametros, cv = i_CV, n_jobs= -1, verbose= 10, scoring= 'accuracy')\n",
        "    start = time()\n",
        "    ml_GridSearchCV.fit(X_train, y_train)\n",
        "    tempo_elapsed= time()-start\n",
        "    #print(f\"\\nGridSearchCV levou {tempo_elapsed:.2f} segundos.\")\n",
        "\n",
        "    # Parâmetros que otimizam a classificação:\n",
        "    print(f'\\nParametros otimizados: {ml_GridSearchCV.best_params_}')\n",
        "    \n",
        "    if ml_Opt == 'ml_DT2':\n",
        "        print(f'\\nDecisionTreeClassifier *********************************************************************************************************')\n",
        "        ml_Opt = DecisionTreeClassifier(criterion= ml_GridSearchCV.best_params_['criterion'], \n",
        "                                        max_depth= ml_GridSearchCV.best_params_['max_depth'],\n",
        "                                        max_leaf_nodes= ml_GridSearchCV.best_params_['max_leaf_nodes'],\n",
        "                                        min_samples_split= ml_GridSearchCV.best_params_['min_samples_leaf'],\n",
        "                                        min_samples_leaf= ml_GridSearchCV.best_params_['min_samples_split'], \n",
        "                                        random_state= i_Seed)\n",
        "        \n",
        "    elif ml_Opt == 'ml_RF2':\n",
        "        print(f'\\nRandomForestClassifier *********************************************************************************************************')\n",
        "        ml_Opt = RandomForestClassifier(bootstrap= ml_GridSearchCV.best_params_['bootstrap'], \n",
        "                                        max_depth= ml_GridSearchCV.best_params_['max_depth'],\n",
        "                                        max_features= ml_GridSearchCV.best_params_['max_features'],\n",
        "                                        min_samples_leaf= ml_GridSearchCV.best_params_['min_samples_leaf'],\n",
        "                                        min_samples_split= ml_GridSearchCV.best_params_['min_samples_split'],\n",
        "                                        n_estimators= ml_GridSearchCV.best_params_['n_estimators'],\n",
        "                                        random_state= i_Seed)\n",
        "        \n",
        "    elif ml_Opt == 'ml_AB2':\n",
        "        print(f'\\nAdaBoostClassifier *********************************************************************************************************')\n",
        "        ml_Opt = AdaBoostClassifier(algorithm='SAMME.R', \n",
        "                                    base_estimator=RandomForestClassifier(bootstrap = False, \n",
        "                                                                          max_depth = 10, \n",
        "                                                                          max_features = 'auto', \n",
        "                                                                          min_samples_leaf = 1, \n",
        "                                                                          min_samples_split = 2, \n",
        "                                                                          n_estimators = 400), \n",
        "                                    learning_rate = ml_GridSearchCV.best_params_['learning_rate'], \n",
        "                                    n_estimators = ml_GridSearchCV.best_params_['n_estimators'], \n",
        "                                    random_state = i_Seed)\n",
        "        \n",
        "    elif ml_Opt == 'ml_GB2':\n",
        "        print(f'\\nGradientBoostingClassifier *********************************************************************************************************')\n",
        "        ml_Opt = GradientBoostingClassifier(learning_rate = ml_GridSearchCV.best_params_['learning_rate'], \n",
        "                                            n_estimators = ml_GridSearchCV.best_params_['n_estimators'], \n",
        "                                            max_depth = ml_GridSearchCV.best_params_['max_depth'], \n",
        "                                            min_samples_split = ml_GridSearchCV.best_params_['min_samples_split'], \n",
        "                                            min_samples_leaf = ml_GridSearchCV.best_params_['min_samples_leaf'], \n",
        "                                            max_features = ml_GridSearchCV.best_params_['max_features'])\n",
        "        \n",
        "    elif ml_Opt == 'ml_XGB2':\n",
        "        print(f'\\nXGBoostingClassifier *********************************************************************************************************')\n",
        "        ml_Opt = XGBoostingClassifier(learning_rate= ml_GridSearchCV.best_params_['learning_rate'], \n",
        "                                      max_depth= ml_GridSearchCV.best_params_['max_depth'], \n",
        "                                      colsample_bytree= ml_GridSearchCV.best_params_['colsample_bytree'], \n",
        "                                      subsample= ml_GridSearchCV.best_params_['subsample'], \n",
        "                                      gamma= ml_GridSearchCV.best_params_['gamma'], \n",
        "                                      min_child_weight= ml_GridSearchCV.best_params_['min_child_weight'])\n",
        "        \n",
        "    # Treina novamente usando os parametros otimizados...\n",
        "    ml_Opt.fit(X_train, y_train)\n",
        "\n",
        "    # Cross-Validation com 10 folds\n",
        "    print(f'\\n********* CROSS-VALIDATION ***********')\n",
        "    a_scores_CV = cross_val_score(ml_Opt, X_train, y_train, cv = i_CV)\n",
        "    print(f'Média das Acurácias calculadas pelo CV....: {100*round(a_scores_CV.mean(),4)}')\n",
        "    print(f'std médio das Acurácias calculadas pelo CV: {100*round(a_scores_CV.std(),4)}')\n",
        "\n",
        "    # Faz predições com os parametros otimizados...\n",
        "    y_pred = ml_Opt.predict(X_test)\n",
        "  \n",
        "    # Importância das COLUNAS\n",
        "    print(f'\\n********* IMPORTÂNCIA DAS COLUNAS ***********')\n",
        "    df_importancia_variaveis = pd.DataFrame(zip(l_colunas, ml_Opt.feature_importances_), columns= ['coluna', 'importancia'])\n",
        "    df_importancia_variaveis = df_importancia_variaveis.sort_values(by= ['importancia'], ascending=False)\n",
        "    print(df_importancia_variaveis)\n",
        "\n",
        "    # Matriz de Confusão\n",
        "    print(f'\\n********* CONFUSION MATRIX - PARAMETER TUNNING ***********')\n",
        "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    cf_labels = ['True_Negative', 'False_Positive', 'False_Negative', 'True_Positive']\n",
        "    cf_categories = ['Zero', 'One']\n",
        "    mostra_confusion_matrix(cf_matrix, group_names = cf_labels, categories = cf_categories)\n",
        "\n",
        "    return ml_Opt, ml_GridSearchCV.best_params_"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAHC7295jkFA",
        "outputId": "8b62b2ca-2b6d-41f2-bffd-e8ddf42b5e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Invoca a função\n",
        "ml_DT2, best_params = GridSearchOptimizer(ml_DT, 'ml_DT2', d_parametros_DT, X_treinamento, y_treinamento, X_teste, y_teste, cv = i_CV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 5250 candidates, totalling 52500 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1123s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.2s\n",
            "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    1.8s\n",
            "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:    2.9s\n",
            "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    5.2s\n",
            "[Parallel(n_jobs=-1)]: Done  88 tasks      | elapsed:    6.5s\n",
            "[Parallel(n_jobs=-1)]: Done 110 tasks      | elapsed:    8.0s\n",
            "[Parallel(n_jobs=-1)]: Done 132 tasks      | elapsed:    9.7s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   11.6s\n",
            "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   13.4s\n",
            "[Parallel(n_jobs=-1)]: Done 214 tasks      | elapsed:   15.6s\n",
            "[Parallel(n_jobs=-1)]: Done 244 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=-1)]: Done 278 tasks      | elapsed:   20.2s\n",
            "[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   22.6s\n",
            "[Parallel(n_jobs=-1)]: Done 350 tasks      | elapsed:   25.4s\n",
            "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:   28.1s\n",
            "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:   31.2s\n",
            "[Parallel(n_jobs=-1)]: Done 472 tasks      | elapsed:   34.1s\n",
            "[Parallel(n_jobs=-1)]: Done 518 tasks      | elapsed:   37.4s\n",
            "[Parallel(n_jobs=-1)]: Done 564 tasks      | elapsed:   40.7s\n",
            "[Parallel(n_jobs=-1)]: Done 614 tasks      | elapsed:   44.3s\n",
            "[Parallel(n_jobs=-1)]: Done 664 tasks      | elapsed:   47.8s\n",
            "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:   51.7s\n",
            "[Parallel(n_jobs=-1)]: Done 772 tasks      | elapsed:   55.0s\n",
            "[Parallel(n_jobs=-1)]: Done 830 tasks      | elapsed:   58.3s\n",
            "[Parallel(n_jobs=-1)]: Done 888 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 950 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1012 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=-1)]: Done 1078 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 1214 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1284 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1358 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1432 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=-1)]: Done 1510 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=-1)]: Done 1588 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=-1)]: Done 1670 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 1838 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=-1)]: Done 1924 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=-1)]: Done 2014 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=-1)]: Done 2104 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done 2198 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=-1)]: Done 2292 tasks      | elapsed:  2.5min\n",
            "[Parallel(n_jobs=-1)]: Done 2390 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=-1)]: Done 2488 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=-1)]: Done 2590 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done 2692 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=-1)]: Done 2798 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=-1)]: Done 2904 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=-1)]: Done 3014 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done 3124 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=-1)]: Done 3238 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=-1)]: Done 3352 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=-1)]: Done 3470 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=-1)]: Done 3588 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=-1)]: Done 3710 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=-1)]: Done 3832 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=-1)]: Done 3958 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=-1)]: Done 4084 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=-1)]: Done 4214 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=-1)]: Done 4344 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=-1)]: Done 4478 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=-1)]: Done 4612 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done 4750 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=-1)]: Done 4888 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=-1)]: Done 5030 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=-1)]: Done 5172 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=-1)]: Done 5318 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=-1)]: Done 5464 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=-1)]: Done 5614 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=-1)]: Done 5764 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=-1)]: Done 5918 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=-1)]: Done 6072 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=-1)]: Done 6230 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=-1)]: Done 6388 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=-1)]: Done 6550 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=-1)]: Done 6712 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=-1)]: Done 6878 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=-1)]: Done 7044 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=-1)]: Done 7214 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=-1)]: Done 7384 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=-1)]: Done 7558 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=-1)]: Done 7732 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=-1)]: Done 7910 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=-1)]: Done 8088 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=-1)]: Done 8270 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=-1)]: Done 8452 tasks      | elapsed:  8.9min\n",
            "[Parallel(n_jobs=-1)]: Done 8638 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=-1)]: Done 8824 tasks      | elapsed:  9.2min\n",
            "[Parallel(n_jobs=-1)]: Done 9014 tasks      | elapsed:  9.4min\n",
            "[Parallel(n_jobs=-1)]: Done 9204 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=-1)]: Done 9398 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=-1)]: Done 9592 tasks      | elapsed:  9.9min\n",
            "[Parallel(n_jobs=-1)]: Done 9790 tasks      | elapsed: 10.1min\n",
            "[Parallel(n_jobs=-1)]: Done 9988 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=-1)]: Done 10190 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=-1)]: Done 10392 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=-1)]: Done 10598 tasks      | elapsed: 10.8min\n",
            "[Parallel(n_jobs=-1)]: Done 10804 tasks      | elapsed: 11.0min\n",
            "[Parallel(n_jobs=-1)]: Done 11014 tasks      | elapsed: 11.3min\n",
            "[Parallel(n_jobs=-1)]: Done 11224 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=-1)]: Done 11438 tasks      | elapsed: 11.7min\n",
            "[Parallel(n_jobs=-1)]: Done 11652 tasks      | elapsed: 11.9min\n",
            "[Parallel(n_jobs=-1)]: Done 11870 tasks      | elapsed: 12.1min\n",
            "[Parallel(n_jobs=-1)]: Done 12088 tasks      | elapsed: 12.3min\n",
            "[Parallel(n_jobs=-1)]: Done 12310 tasks      | elapsed: 12.6min\n",
            "[Parallel(n_jobs=-1)]: Done 12532 tasks      | elapsed: 12.9min\n",
            "[Parallel(n_jobs=-1)]: Done 12758 tasks      | elapsed: 13.1min\n",
            "[Parallel(n_jobs=-1)]: Done 12984 tasks      | elapsed: 13.5min\n",
            "[Parallel(n_jobs=-1)]: Done 13214 tasks      | elapsed: 13.8min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfXXGaYMju1V",
        "outputId": "3493c2e8-53eb-4c37-c4f4-fb8cf0595848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.externals.six import StringIO  \n",
        "from IPython.display import Image  \n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(ml_DT2, out_file = dot_data, filled = True, rounded = True, special_characters = True, feature_names = l_colunas, class_names = ['0','1'])\n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('DecisionTree.png')\n",
        "Image(graph.create_png())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-ba708c5e99bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_DT2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdot_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_colunas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ml_DT2' is not defined"
          ]
        }
      ]
    }
  ]
}